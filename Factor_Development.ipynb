{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df08974",
   "metadata": {
    "cellUniqueIdByVincent": "88e34"
   },
   "source": [
    "# EquiLend Factor Development Notebook\n",
    "*Interactive development and testing of new factors*\n",
    "\n",
    "Use this notebook for:\n",
    "- üß™ **Experimenting with new factor ideas**\n",
    "- üìä **Testing factor performance on historical data**\n",
    "- üîç **Debugging and refining factor calculations**\n",
    "- üìà **Visualizing factor behavior and distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35771b17",
   "metadata": {
    "cellUniqueIdByVincent": "7e753"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "\n",
    "# Import existing factor classes for comparison\n",
    "sys.path.append('../models')\n",
    "from core_factors import ShortInterestMomentum, BorrowCostShock\n",
    "\n",
    "print(f\"Factor Development Environment - {date.today()}\")\n",
    "print(\"Ready for interactive factor development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d2519",
   "metadata": {
    "cellUniqueIdByVincent": "4353d"
   },
   "source": [
    "## 1. Load Test Data\n",
    "\n",
    "Start with sample or historical data for testing new factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec807d",
   "metadata": {
    "cellUniqueIdByVincent": "9b33a"
   },
   "outputs": [],
   "source": [
    "# Create sample data for testing\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2024-01-01', periods=100, freq='D')\n",
    "tickers = [f'STOCK_{i:02d}' for i in range(20)]\n",
    "\n",
    "# Generate sample securities lending data\n",
    "data = []\n",
    "for date in dates:\n",
    "    for ticker in tickers:\n",
    "        data.append({\n",
    "            'Date': date,\n",
    "            'ticker': ticker,\n",
    "            'Fee All (BPS)': np.random.uniform(10, 500),\n",
    "            'Active Utilization (%)': np.random.uniform(1, 95),\n",
    "            'On Loan Quantity': np.random.uniform(100000, 10000000),\n",
    "            'Short Interest': np.random.uniform(1000000, 50000000),\n",
    "            'Average Daily Volume': np.random.uniform(500000, 5000000)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Test dataset: {len(df)} rows, {df['Date'].nunique()} dates, {df['ticker'].nunique()} tickers\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec55f2",
   "metadata": {
    "cellUniqueIdByVincent": "15e81"
   },
   "source": [
    "## 2. Develop New Factor Ideas\n",
    "\n",
    "This section is for experimenting with new factor concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51840f",
   "metadata": {
    "cellUniqueIdByVincent": "ddd2f"
   },
   "outputs": [],
   "source": [
    "# Example: Develop a new \"Fee Volatility Spike\" factor\n",
    "class FeeVolatilitySpike:\n",
    "    \"\"\"Detect sudden spikes in fee volatility - experimental factor\"\"\"\n",
    "    \n",
    "    def __init__(self, fee_col='Fee All (BPS)', window=20, spike_threshold=2.0):\n",
    "        self.fee_col = fee_col\n",
    "        self.window = window\n",
    "        self.spike_threshold = spike_threshold\n",
    "    \n",
    "    def calculate(self, df):\n",
    "        \"\"\"Calculate fee volatility spike factor\"\"\"\n",
    "        # Group by ticker for time series calculations\n",
    "        results = []\n",
    "        \n",
    "        for ticker in df['ticker'].unique():\n",
    "            ticker_data = df[df['ticker'] == ticker].sort_values('Date')\n",
    "            \n",
    "            # Calculate rolling volatility\n",
    "            fee_returns = ticker_data[self.fee_col].pct_change()\n",
    "            rolling_vol = fee_returns.rolling(self.window).std()\n",
    "            \n",
    "            # Detect spikes: current vol vs average vol\n",
    "            avg_vol = rolling_vol.rolling(self.window * 2).mean()\n",
    "            vol_spike = rolling_vol / avg_vol\n",
    "            \n",
    "            # Create factor scores\n",
    "            ticker_data = ticker_data.copy()\n",
    "            ticker_data['Fee_Vol_Spike'] = vol_spike\n",
    "            ticker_data['Vol_Spike_Flag'] = (vol_spike > self.spike_threshold).astype(int)\n",
    "            \n",
    "            results.append(ticker_data)\n",
    "        \n",
    "        return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Test the new factor\n",
    "fvs = FeeVolatilitySpike()\n",
    "df_with_new_factor = fvs.calculate(df)\n",
    "\n",
    "print(\"New Factor Statistics:\")\n",
    "print(df_with_new_factor[['Fee_Vol_Spike', 'Vol_Spike_Flag']].describe())\n",
    "\n",
    "# Visualize the new factor\n",
    "plt.figure(figsize=(12, 4))\n",
    "df_with_new_factor['Fee_Vol_Spike'].hist(bins=30, alpha=0.7)\n",
    "plt.title('Fee Volatility Spike Factor Distribution')\n",
    "plt.xlabel('Volatility Spike Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(2.0, color='red', linestyle='--', label='Spike Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e4bbf",
   "metadata": {
    "cellUniqueIdByVincent": "6fdca"
   },
   "source": [
    "## 3. Compare with Existing Factors\n",
    "\n",
    "Test how the new factor performs relative to existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b101d7",
   "metadata": {
    "cellUniqueIdByVincent": "2f532"
   },
   "outputs": [],
   "source": [
    "# Compare with existing factors\n",
    "sim = ShortInterestMomentum()\n",
    "bcs = BorrowCostShock()\n",
    "\n",
    "# Add existing factors for comparison\n",
    "try:\n",
    "    df_comparison = df_with_new_factor.copy()\n",
    "    df_comparison['SIM'] = sim.score(df_comparison)\n",
    "    df_comparison['BCS'] = bcs.score(df_comparison)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    factor_cols = ['Fee_Vol_Spike', 'SIM', 'BCS']\n",
    "    available_cols = [col for col in factor_cols if col in df_comparison.columns]\n",
    "    \n",
    "    if len(available_cols) > 1:\n",
    "        correlation_matrix = df_comparison[available_cols].corr()\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, square=True)\n",
    "        plt.title('Factor Correlation: New vs Existing')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nFactor Correlations:\")\n",
    "        print(correlation_matrix)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not compute all factor comparisons: {e}\")\n",
    "    print(\"This is normal when developing new factors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67937e7d",
   "metadata": {
    "cellUniqueIdByVincent": "4d0df"
   },
   "source": [
    "## 4. Performance Testing\n",
    "\n",
    "Test factor performance with synthetic or historical returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593b7b7",
   "metadata": {
    "cellUniqueIdByVincent": "c9e6a"
   },
   "outputs": [],
   "source": [
    "# Generate synthetic forward returns for testing\n",
    "np.random.seed(456)\n",
    "df_with_new_factor['Forward_Return_5D'] = np.random.normal(0, 0.02, len(df_with_new_factor))\n",
    "\n",
    "# Test predictive power\n",
    "def test_factor_performance(df, factor_col, return_col='Forward_Return_5D'):\n",
    "    \"\"\"Simple IC test for factor performance\"\"\"\n",
    "    valid_data = df[[factor_col, return_col]].dropna()\n",
    "    \n",
    "    if len(valid_data) < 20:\n",
    "        return {'IC': 0, 'Hit_Rate': 0.5, 'N': len(valid_data)}\n",
    "    \n",
    "    ic = valid_data[factor_col].corr(valid_data[return_col])\n",
    "    \n",
    "    # Quintile analysis\n",
    "    valid_data['Quintile'] = pd.qcut(valid_data[factor_col], 5, labels=False)\n",
    "    quintile_returns = valid_data.groupby('Quintile')[return_col].mean()\n",
    "    \n",
    "    # Hit rate: top quintile outperforms bottom quintile\n",
    "    hit_rate = (quintile_returns.iloc[-1] > quintile_returns.iloc[0])\n",
    "    \n",
    "    return {\n",
    "        'IC': ic,\n",
    "        'Hit_Rate': hit_rate,\n",
    "        'Top_Quintile_Return': quintile_returns.iloc[-1],\n",
    "        'Bottom_Quintile_Return': quintile_returns.iloc[0],\n",
    "        'N': len(valid_data)\n",
    "    }\n",
    "\n",
    "# Test the new factor\n",
    "performance = test_factor_performance(df_with_new_factor, 'Fee_Vol_Spike')\n",
    "\n",
    "print(\"New Factor Performance Test:\")\n",
    "print(f\"Information Coefficient: {performance['IC']:.4f}\")\n",
    "print(f\"Hit Rate (Top > Bottom): {performance['Hit_Rate']}\")\n",
    "print(f\"Top Quintile Return: {performance['Top_Quintile_Return']:.4f}\")\n",
    "print(f\"Bottom Quintile Return: {performance['Bottom_Quintile_Return']:.4f}\")\n",
    "print(f\"Sample Size: {performance['N']}\")\n",
    "\n",
    "print(\"\\nüìù Development Notes:\")\n",
    "print(\"- This is synthetic data for demonstration\")\n",
    "print(\"- Real testing requires historical price data\")\n",
    "print(\"- Consider regime analysis and stability testing\")\n",
    "print(\"- Factor may need refinement based on results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982d579",
   "metadata": {
    "cellUniqueIdByVincent": "254e3"
   },
   "source": [
    "## 5. Export Successful Factors\n",
    "\n",
    "Once a factor shows promise, export it to the models module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127098b",
   "metadata": {
    "cellUniqueIdByVincent": "d878f"
   },
   "outputs": [],
   "source": [
    "# Example: Export new factor to models\n",
    "def export_factor_to_module(factor_class, factor_name, module_path='../models/experimental_factors.py'):\n",
    "    \"\"\"Helper to export successful factors to a module file\"\"\"\n",
    "    \n",
    "    import inspect\n",
    "    import os\n",
    "    \n",
    "    # Get the source code of the class\n",
    "    source_code = inspect.getsource(factor_class)\n",
    "    \n",
    "    # Create or append to experimental factors module\n",
    "    header = '''# Experimental Factors\n",
    "# New factors under development and testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "'''\n",
    "    \n",
    "    if not os.path.exists(module_path):\n",
    "        with open(module_path, 'w') as f:\n",
    "            f.write(header)\n",
    "    \n",
    "    # Append the new factor\n",
    "    with open(module_path, 'a') as f:\n",
    "        f.write(f\"\\n\\n# {factor_name}\\n\")\n",
    "        f.write(source_code)\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Factor '{factor_name}' exported to {module_path}\")\n",
    "\n",
    "# Export our experimental factor\n",
    "# export_factor_to_module(FeeVolatilitySpike, \"Fee Volatility Spike Factor\")\n",
    "\n",
    "print(\"üí° Factor Development Complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Test with real historical data\")\n",
    "print(\"2. Validate on out-of-sample period\")\n",
    "print(\"3. Export to production models if successful\")\n",
    "print(\"4. Integrate into daily analysis workflow\")"
   ]
  }
 ],
 "metadata": {
  "vincent": {
   "sessionId": "c99783b7d7a23b8c1dd897a9_2025-06-29T20-12-55-246Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
